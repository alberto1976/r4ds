# Análisis de datos exploratorio

## Introducción

Este capítulo le mostrará cómo usar la visualización y la transformación para explorar sus datos de manera sistemática, una tarea que los estadísticos llaman análisis exploratorio de datos o ADE para abreviar. ADE es un ciclo iterativo. Usted:

1. Genera preguntas sobre sus datos.

1. Busca respuestas al visualizar, transformar y modelar sus datos.

1. Use lo que aprenda para refinar sus preguntas y/o generar nuevas.

El ADE no es un proceso formal con un estricto conjunto de reglas. Más que nada, el ADE es un estado de ánimo. Durante las fases iniciales del ADE usted debe sentirse libre de investigar cada idea que se le ocurra. Algunas de estas ideas se desarrollarán, y algunos serán callejones sin salida. A medida que su exploración continúe, perfeccionará en algunas áreas particularmente productivas que eventualmente escribirá y comunicará a otros.

El ADE es una parte importante de cualquier análisis de datos, incluso si las preguntas se le entregan en un disco, porque siempre tiene que investigar la calidad de sus datos. La limpieza de datos es sólo una aplicación del ADE: usted hace preguntas sobre si sus datos cumplen sus expectativas o no. Para limpiar los datos, necesitará desplegar todas las herramientas de ADE: visualización, transformación y modelado.

### Pre-requisitos

En este capítulo vamos a combinar lo que ha aprendido acerca de dplyr y ggplot2 para hacer interactivamente preguntas, responderlas con datos y luego hacer nuevas preguntas.

```{r setup, message = FALSE}
library(tidyverse)
```

## Preguntas

> "No hay preguntas estadísticas de rutina, sólo rutinas estadísticas
> cuestionables." --- Sir David Cox

> "Mucho mejor una respuesta aproximada a la pregunta correcta, que a
> menudo es vaga, que una respuesta exacta a la pregunta equivocada, que
> siempre puede ser precisa." --- John Tukey

Su meta durante el ADE es desarrollar una comprensión de sus datos. La forma más fácil de hacerlo es utilizar preguntas como herramientas para guiar su investigación. Cuando hace una pregunta, la pregunta centra su atención en una parte específica de su conjunto de datos y le ayuda a decidir qué gráficos, modelos o transformaciones se deben hacer.

El ADE es fundamentalmente un proceso creativo. Y al igual que la mayoría de los procesos creativos, la clave para hacer preguntas de calidad es generar una gran cantidad de preguntas. Es difícil hacer preguntas reveladoras al comienzo de su análisis porque no sabe qué ideas están contenidas en su conjunto de datos. Por otra parte, cada nueva pregunta que usted formula le expondrá a un nuevo aspecto de sus datos y aumentará su ocasión de hacer un descubrimiento. Usted puede rápidamente hurgar en las partes más interesantes de sus datos ---y desarrollar un sistema de preguntas sugerentes--- si sigue cada pregunta con una nueva pregunta basada en lo que usted encuentra.

No hay ninguna regla sobre qué preguntas debe hacer para guiar su investigación. Sin embargo, dos tipos de preguntas siempre serán útiles para hacer descubrimientos dentro de sus datos. Usted puede formular libremente estas preguntas así:

1. Qué tipo de variación ocurre dentro de mis variables?

1. Qué tipo de covariación ocurre entre mis variables?

El resto de este capítulo examinará estas dos preguntas. Voy a explicar qué es variación y qué covariación, y le mostraré varias maneras de responder a cada pregunta. Para facilitar la discusión, definamos algunos términos:

*   Una __variable__ es una cantidad, calidad o propiedad que puede           medirse. 

*   Un __valor__ es el estado de una variable cuando se mide. El valor de     una variable puede cambiar de medida a medida.
  
*   Una __observación__ es un conjunto de mediciones realizadas en            condiciones similares (normalmente se realizan todas las mediciones en     una observación al mismo tiempo y en el mismo objeto). Una observación     contendrá varios valores, cada uno asociado con una variable              diferente. A veces me referiré a una observación como un punto de         datos.

*   __Datos tabulares__ es un conjunto de valores, cada uno asociado con      una variable y una observación. Los datos tabulares están                 _organizados_ si cada valor se coloca en su propia "celda", cada          variable en su propia columna y cada observación en su propia fila. 

Hasta ahora, todos los datos que ha visto han sido ordenados. En la vida real, la mayoría de los datos no están ordenados, por lo que volveremos a estas ideas de nuevo en [datos ordenados].

## Variación

La **variación** es la tendencia de los valores de una variable a cambiar de medida a medida. Usted puede ver la variación fácilmente en la vida real; si mide cualquier variable continua dos veces, obtendrá dos resultados diferentes. Esto es cierto incluso si se miden cantidades constantes, como la velocidad de la luz. Cada una de sus medidas incluirá una pequeña cantidad de error que varía de una medición a otra. Las variables categóricas también pueden variar si se miden a través de diferentes sujetos (por ejemplo, los colores de los ojos de diferentes personas), o tiempos diferentes (por ejemplo, los niveles de energía de un electrón en diferentes momentos).
Cada variable tiene su propio patrón de variación, que puede revelar información interesante. La mejor manera de entender ese patrón es visualizar la distribución de los valores de la variable.

### Visualización de distribuciones

La manera de visualizar la distribución de una variable dependerá de si la variable es categórica o continua. Una variable es **categórica** si sólo puede tomar un pequeño conjunto de valores. En R, las variables categóricas suelen guardarse como factores o vectores de caracteres. Para examinar la distribución de una variable categórica, utilice un gráfico de barras:

```{r}
ggplot(data = diamonds) +
  geom_bar(mapping = aes(x = cut))
```

La altura de las barras muestra cuántas observaciones ocurrieron con cada valor de x. Puede calcular estos valores manualmente con `dplyr::count()`:

```{r}
diamonds %>% 
  count(cut)
```

Una variable es **continua** si puede tomar cualquiera de un conjunto infinito de valores ordenados. Los números y las fechas son dos ejemplos de variables continuas. Para examinar la distribución de una variable continua, utilice un histograma:

```{r}
ggplot(data = diamonds) +
  geom_histogram(mapping = aes(x = carat), binwidth = 0.5)
```

Puede calcular esto a mano combinando `dplyr::count()` y `ggplot2::cut_width()`:

```{r}
diamonds %>% 
  count(cut_width(carat, 0.5))
```

Un histograma divide el eje x en compartimientos igualmente espaciados y luego usa la altura de una barra para mostrar el número de observaciones que caen en cada compartimiento. En el gráfico anterior, la barra más alta muestra que casi 30.000 observaciones tienen un valor de `carat` entre 0,25 y 0,75, que son los bordes izquierdo y derecho de la barra.

Puede definir el ancho de los intervalos en un histograma con el argumento `binwidth`, que se mide en las unidades de la variable `x`. Siempre debe explorar una variedad de binwidths cuando se trabaja con histogramas, ya que binwidths diferentes pueden revelar diferentes patrones. Por ejemplo, aquí es cómo la gráfica de arriba se ve cuando hacemos zoom en sólo los diamantes con un tamaño de menos de tres quilates y se elige un binwidth más pequeño.

```{r}
smaller <- diamonds %>% 
  filter(carat < 3)
  
ggplot(data = smaller, mapping = aes(x = carat)) +
  geom_histogram(binwidth = 0.1)
```

Si desea superponer varios histogramas en el mismo gráfico, le recomiendo usar `geom_freqpoly()` en lugar de `geom_histogram()`. `geom_freqpoly()` realiza el mismo cálculo que `geom_histogram()`, pero en vez de mostrar las cuentas con barras, usa líneas en su lugar. Es mucho más fácil entender líneas superpuestas que barras.

```{r}
ggplot(data = smaller, mapping = aes(x = carat, colour = cut)) +
  geom_freqpoly(binwidth = 0.1)
```

Hay algunos desafíos con este tipo de gráfico, a los que volveremos en [visualización de una variable categórica y una variable continua](#cat-cont).

Ahora que puede visualizar la variación, ¿qué debe buscar en sus gráficos? ¿Y qué tipo de preguntas de seguimiento debe hacer? He reunido una lista a continuación de los tipos de información más útiles que encontrará en sus gráficos, junto con algunas preguntas de seguimiento para cada tipo de información. La clave para hacer buenas preguntas de seguimiento será confiar en su curiosidad (¿Sobre qué quiere aprender más?), Así como su escepticismo (¿Cómo podría esto ser engañoso?).

### Valores típicos

Tanto en los gráficos de barras como en los histogramas, las barras altas muestran los valores comunes de una variable y las barras más cortas muestran valores menos comunes. Los lugares que no tienen barras revelan valores que no se vieron en los datos. Para convertir esta información en preguntas útiles, busque algo inesperado:

* ¿Qué valores son los más comunes? ¿Por qué?

* ¿Qué valores son raros? ¿Por qué? ¿Eso coincide con sus expectativas?

* ¿Puede ver algún patrón inusual? ¿Qué podría explicarlos?

Como ejemplo, el siguiente histograma sugiere varias preguntas interesantes:

* ¿Por qué hay más diamantes en quilates enteros y fracciones comunes de      quilates?

* ¿Por qué hay más diamantes ligeramente a la derecha de cada pico que los    que hay ligeramente a la izquierda de cada pico?
  
* ¿Por qué no hay diamantes más grandes de 3 quilates?

```{r}
ggplot(data = smaller, mapping = aes(x = carat)) +
  geom_histogram(binwidth = 0.01)
```

Los clústeres de valores similares sugieren que existen subgrupos en sus datos. Para entender los subgrupos, pregunte:

* ¿Cómo se comparan entre sí las observaciones dentro de cada grupo?

* ¿Cómo se diferencian entre sí las observaciones en clústeres separados?

* ¿Cómo se pueden explicar o describir los clusters?

* ¿Por qué la aparición de clusters puede ser engañosa?

El histograma a continuación muestra la longitud (en minutos) de 272 erupciones del géiser Old Faithful en el Parque Nacional de Yellowstone. Los tiempos de erupción parecen estar agrupados en dos grupos: hay erupciones cortas (de alrededor de 2 minutos) y erupciones largas (4-5 minutos), pero pocas en el medio.

```{r}
ggplot(data = faithful, mapping = aes(x = eruptions)) + 
  geom_histogram(binwidth = 0.25)
```  

Muchas de las preguntas anteriores le inducirán a explorar una relación *entre* variables, por ejemplo, para ver si los valores de una variable pueden explicar el comportamiento de otra variable. Llegaremos a eso en breve.

### Valores inusuales

Los valores atípicos son observaciones que son inusuales; puntos de datos que no parecen ajustarse al patrón. A veces los valores atípicos son errores de entrada de datos; Otras veces los atípicos sugieren una nueva ciencia importante. Cuando se tiene una gran cantidad de datos, los valores extremos a veces son difíciles de ver en un histograma. Por ejemplo, tome la distribución de la variable `y` del conjunto de datos diamantes. La única evidencia de los valores atípicos son los límites inusualmente amplios del eje y.

```{r}
ggplot(diamonds) + 
  geom_histogram(mapping = aes(x = y), binwidth = 0.5)
```   

Hay tantas observaciones en los compartimientos comunes que los compartimientos raros son tan cortos que usted no puede verlos (aunque quizá si usted mira fijamente en el 0 notará algo). Para que sea fácil ver los valores inusuales, necesitamos hacer zoom en pequeños valores del eje y con `coord_cartesian()`:

```{r}
ggplot(diamonds) + 
  geom_histogram(mapping = aes(x = y), binwidth = 0.5) +
  coord_cartesian(ylim = c(0, 50))
```   

(`coord_cartesian()` también tiene un argumento `xlim()` para cuando necesita hacer zoom en el eje x. ggplot2 también tiene funciones `xlim()` y `ylim()` que trabajan ligeramente distinto: lanzan los datos fuera de los límites.)

Esto nos permite ver que hay tres valores inusuales: 0, ~30 y ~60. Los arrancamos con dplyr:

```{r, include = FALSE}
old <- options(tibble.print_max = 10, tibble.print_min = 10)
```

```{r}
unusual <- diamonds %>% 
  filter(y < 3 | y > 20) %>% 
  arrange(y)
unusual
```

```{r, include = FALSE}
options(old)
```

La variable `y` mide una de las tres dimensiones de estos diamantes, en mm. Sabemos que los diamantes no pueden tener un ancho de 0 mm, por lo que estos valores deben ser incorrectos. También podríamos sospechar que las medidas de 32mm y 59mm son inverosímiles: ¡esos diamantes tienen más de una pulgada de largo, pero no cuestan cientos de miles de dólares!

Es una buena práctica repetir su análisis con y sin los valores atípicos. Si tienen un efecto mínimo en los resultados, y no puede averiguar por qué están allí, es razonable reemplazarlos con valores perdidos y seguir adelante. Sin embargo, si tienen un efecto sustancial en sus resultados, no debe dejarlos sin justificación. Tendrá que averiguar qué los causó (por ejemplo, un error en la introducción de datos) y revelar que los ha eliminado en su informe.


### Ejercicios

1.  Explore la distribución de cada una de las variables `x`,` y` y `z` 
    en `diamonds`. ¿Qué ve? Piense en un diamante y cómo puede decidir qué      dimensión es la longitud, el ancho y la profundidad.

1.  Explore la distribución del `precio`. ¿Descubre algo inusual o              sorprendente? (Sugerencia: Piense cuidadosamente en la 'binwidth` y         asegúrese de probar una amplia gama de valores.)

1.  ¿Cuántos diamantes son 0,99 quilates? ¿Cuántos son 1 quilate? ¿Cuál cree     que es la causa de la diferencia?
    
1.  Compare y contraste `coord_cartesian()` vs `xlim()` o `ylim()` al           ampliar un histograma. ¿Qué sucede si deja "binwidth" sin configurar?
    ¿Qué sucede si intenta acercarse para que sólo se muestre media barra?
    
## Valores perdidos

Si ha encontrado valores inusuales en su conjunto de datos y simplemente quiere pasar al resto de su análisis, tiene dos opciones.

1.  Eliminar toda la fila con los valores extraños:

    ```{r, eval = FALSE}
    diamonds2 <- diamonds %>% 
      filter(between(y, 3, 20))
    ```
    
    No recomiendo esta opción puesto que sólo porque una medida no sea          válida, no significa que todas las mediciones lo sean. Además, si usted     tiene datos de baja calidad, mientras haya aplicado este enfoque a cada     variable podría encontrar que no tiene ningún dato faltante!

1.  En su lugar, recomiendo reemplazar los valores inusuales con valores        faltantes.
    La forma más fácil de hacerlo es usar `mutate()` para reemplazar la         variable con una copia modificada. Puede utilizar la función `ifelse()`     para sustituir valores no habituales por `NA`:

    ```{r}
    diamonds2 <- diamonds %>% 
      mutate(y = ifelse(y < 3 | y > 20, NA, y))
    ```

`ifelse()` tiene tres argumentos. El primer argumento `test` debería ser un vector lógico. El resultado contendrá el valor del segundo argumento, `yes`, cuando `test` sea `TRUE`, y el valor del tercer argumento, `no`, cuando sea falso.

Al igual que R, ggplot2 se suscribe a la filosofía de que los valores perdidos nunca deben desaparecer en silencio. No es obvio dónde debe graficar valores perdidos, por lo que ggplot2 no los incluye en el gráfico, pero advierte que se han eliminado:

```{r, dev = "png"}
ggplot(data = diamonds2, mapping = aes(x = x, y = y)) + 
  geom_point()
```

Para suprimir esa advertencia, haga `na.rm = TRUE`:

```{r, eval = FALSE}
ggplot(data = diamonds2, mapping = aes(x = x, y = y)) + 
  geom_point(na.rm = TRUE)
```

Otras veces usted quisiera entender qué hace que las observaciones con valores faltantes sean diferentes a las observaciones con valores registrados. Por ejemplo, en `nycflights13::flights`, los valores perdidos en la variable `dep_time` indican que el vuelo ha sido cancelado. Es posible que desee comparar los horarios de salida programados para los horarios cancelados y no cancelados. Puede hacerlo creando una nueva variable con `is.na()`.

```{r}
nycflights13::flights %>% 
  mutate(
    cancelled = is.na(dep_time),
    sched_hour = sched_dep_time %/% 100,
    sched_min = sched_dep_time %% 100,
    sched_dep_time = sched_hour + sched_min / 60
  ) %>% 
  ggplot(mapping = aes(sched_dep_time)) + 
    geom_freqpoly(mapping = aes(colour = cancelled), binwidth = 1/4)
```

Sin embargo este gráfico no es grande porque hay muchos más vuelos no cancelados que vuelos cancelados. En la siguiente sección exploraremos algunas técnicas para mejorar esta comparación.

### Ejercicios

1.  ¿Qué sucede con los valores perdidos en un histograma? ¿Qué sucede con      los valores perdidos en un gráfico de barras? ¿Por qué hay diferencia?

1.  ¿Qué significa `na.rm = TRUE` en `mean()` y en `sum()`?

## Covariación

Si la variación describe el comportamiento _dentro_ de una variable, la covariación describe el comportamiento _entre_ variables. La **Covariación** es la tendencia a que los valores de dos o más variables varíen juntos de una manera relacionada. La mejor manera de detectar la covariación es visualizar la relación entre dos o más variables. La forma de hacerlo dependerá nuevamente del tipo de variables involucradas.

### Una variable categórica y continua {#cat-cont}

Es común querer explorar la distribución de una variable continua desglosada por una variable categórica, como en el polígono de frecuencias anterior. La apariencia por defecto de `geom_freqpoly()` no es tan útil para ese tipo de comparación porque la altura está dada por el recuento. Eso significa que si uno de los grupos es mucho más pequeño que los otros, es difícil ver las diferencias de forma. Por ejemplo, vamos a explorar cómo el precio de un diamante varía con su calidad:

```{r}
ggplot(data = diamonds, mapping = aes(x = price)) + 
  geom_freqpoly(mapping = aes(colour = cut), binwidth = 500)
```

Es difícil ver la diferencia en la distribución porque los recuentos generales difieren mucho:

```{r, fig.width = "50%", fig.width = 4}
ggplot(diamonds) + 
  geom_bar(mapping = aes(x = cut))
```

Para facilitar la comparación necesitamos cambiar lo que se muestra en el eje y. En lugar de mostrar la cuenta, mostraremos la __densidad__, que es el recuento estandarizado de manera que el área bajo cada polígono de frecuencia sea uno....

```{r}
ggplot(data = diamonds, mapping = aes(x = price, y = ..density..)) + 
  geom_freqpoly(mapping = aes(colour = cut), binwidth = 500)
```

Hay algo bastante sorprendente sobre este gráfico - parece que los diamantes claros (la calidad más baja) tienen el precio promedio más alto! Pero tal vez eso se debe a que los polígonos de frecuencia son un poco difíciles de interpretar - hay mucho que hacer en esta ilustración.

Otra alternativa para mostrar la distribución de una variable continua desglosada por una variable categórica es el boxplot. Un **boxplot** es un tipo de taquigrafía visual para una distribución de valores que es popular entre los estadísticos. Cada boxplot consta de:

* Una caja que se extiende desde el percentil 25 de la distribución hasta el   percentil 75, una distancia conocida como rango intercuartil (RIQ). En el   centro de la caja está una línea que muestra la mediana, es decir, el       percentil 50 de la distribución. Estas tres líneas le dan una idea de la    propagación de la distribución y si la distribución es simétrica sobre la   mediana o sesgada a un lado.

* Puntos visuales que muestran observaciones que caen más de 1,5 veces el     RIQ desde cualquier borde de la caja. Estos puntos periféricos son          inusuales por lo que se trazan individualmente.

* Una línea (o bigote) que se extiende desde cada extremo de la caja y va     hasta el punto más alejado de la distribución.

```{r, echo = FALSE, out.width = "100%"}
knitr::include_graphics("images/EDA-boxplot.png")
```

Echemos un vistazo a la distribución del precio por corte usando `geom_boxplot()`:

```{r fig.height = 3}
ggplot(data = diamonds, mapping = aes(x = cut, y = price)) +
  geom_boxplot()
```

Vemos mucho menos información sobre la distribución, pero los boxplots son mucho más compactos para que podamos compararlos más fácilmente (y encajar más en un gráfico). ¡Apoya la conclusión contraintuitiva de que, en promedio, los diamantes de la mejor calidad son más baratos! En los ejercicios, se le desafiará a averiguar por qué.

`cut` es un factor ordenado: claro es peor que bien, que es peor que muy bueno y así sucesivamente. Muchas variables categóricas no tienen un orden intrínseco, por lo que es posible que desee reordenarlas para hacer una presentación más informativa. Una forma de hacerlo es con la función `reorder()`.

Por ejemplo, tome la variable `class` en el conjunto de datos `mpg`. Tal vez le interese saber cómo el kilometraje de la autopista varía según las clases:

```{r}
ggplot(data = mpg, mapping = aes(x = class, y = hwy)) +
  geom_boxplot()
```

Para hacer que la tendencia sea más fácil de ver, podemos reordenar `class` basado en el valor mediano de `hwy`:

```{r fig.height = 3}
ggplot(data = mpg) +
  geom_boxplot(mapping = aes(x = reorder(class, hwy, FUN = median), y = hwy))
```

Si tiene nombres de variables largos, `geom_boxplot()` funcionará mejor si lo voltea 90°. Puede hacerlo con `coord_flip()`.

```{r}
ggplot(data = mpg) +
  geom_boxplot(mapping = aes(x = reorder(class, hwy, FUN = median), y = hwy)) +
  coord_flip()
```

#### Ejercicios

1.  Utilice lo que ha aprendido para mejorar la visualización de los            horarios de salida de vuelos cancelados y no cancelados.

1.  ¿Qué variable en el conjunto de datos de diamantes es más importante        para predecir el precio de un diamante? ¿Cómo se correlaciona esa           variable con el corte?
    ¿Por qué la combinación de esas dos relaciones lleva a que los diamantes     de calidad inferior sean más caros?

1.  Instale el paquete ggstance, y cree un boxplot horizontal.
    ¿Cómo se compara esto con el uso de `coord_flip()`?

1.  Un problema con los boxplots es que se desarrollaron en una era de          conjuntos de datos mucho más pequeños y tienden a mostrar un número         prohibitivamente grande de "valores periféricos". Un enfoque para           remediar este problema es el gráfico de la carta. Instale el paquete        lvplot e intente usar `geom_lv()` para mostrar la distribución de precio     vs corte. ¿Qué ve? ¿Cómo se interpretan los gráficos?

1.  Compare y contraste `geom_violin()` con un facetted `geom_histogram()`,
    o un coloreado `geom_freqpoly()`. ¿Cuáles son los pros y los contras de     cada método?

1.  Si tiene un pequeño conjunto de datos, a veces es útil usar                 `geom_jitter()` para ver la relación entre una variable continua y          una categórica.
    El paquete ggbeeswarm proporciona una serie de métodos similares a          `geom_jitter ()`. Escríbalos y describa brevemente lo que hace cada uno.

### Dos variables categóricas

Para visualizar la covariación entre variables categóricas, necesitará contar el número de observaciones para cada combinación. Una forma de hacerlo es confiar en el `geom_count()`:

```{r}
ggplot(data = diamonds) +
  geom_count(mapping = aes(x = cut, y = color))
```

El tamaño de cada círculo en la gráfica muestra cuántas observaciones ocurrieron en cada combinación de valores. La covariación aparecerá como una fuerte correlación entre los valores de x específicos y los valores de y específicos.

Otro enfoque es calcular el recuento con dplyr:

```{r}
diamonds %>% 
  count(color, cut)
```

Luego visualice con `geom_tile()` y la estética de relleno:

```{r}
diamonds %>% 
  count(color, cut) %>%  
  ggplot(mapping = aes(x = color, y = cut)) +
    geom_tile(mapping = aes(fill = n))
```

Si las variables categóricas están desordenadas, es posible que desee utilizar el paquete de seriación para reordenar las filas y las columnas de forma simultánea para mostrar patrones interesantes más claramente. Para gráficos más grandes, es posible que desee probar los paquetes d3heatmap o heatmaply, que crean gráficos interactivos.

#### Ejercicios

1.  ¿Cómo podría cambiar la escala del conjunto de datos de conteo anterior     para mostrar más claramente la distribución del corte dentro del color o     del color dentro del corte?

1.  Utilice `geom_tile()` junto con dplyr para explorar cómo los retrasos       promedio de los vuelos varían según el destino y el mes del año. ¿Qué       hace que la trama sea difícil de leer? ¿Cómo podría mejorarlo?

1.  Por qué es ligeramente mejor usar `aes(x = color, y = cut)` en lugar
    de `aes(x = cut, y = color)` en el ejemplo anterior?

### Two continuous variables

You've already seen one great way to visualise the covariation between two continuous variables: draw a scatterplot with `geom_point()`. You can see covariation as a pattern in the points. For example, you can see an exponential relationship between the carat size and price of a diamond.

```{r, dev = "png"}
ggplot(data = diamonds) +
  geom_point(mapping = aes(x = carat, y = price))
```

Scatterplots become less useful as the size of your dataset grows, because points begin to overplot, and pile up into areas of uniform black (as above).
You've already seen one way to fix the problem: using the `alpha` aesthetic to add transparency.

```{r, dev = "png"}
ggplot(data = diamonds) + 
  geom_point(mapping = aes(x = carat, y = price), alpha = 1 / 100)
```

But using transparency can be challenging for very large datasets. Another solution is to use bin. Previously you used `geom_histogram()` and `geom_freqpoly()` to bin in one dimension. Now you'll learn how to use `geom_bin2d()` and `geom_hex()` to bin in two dimensions.

`geom_bin2d()` and `geom_hex()` divide the coordinate plane into 2d bins and then use a fill color to display how many points fall into each bin. `geom_bin2d()` creates rectangular bins. `geom_hex()` creates hexagonal bins. You will need to install the hexbin package to use `geom_hex()`.

```{r, fig.asp = 1, out.width = "50%", fig.align = "default"}
ggplot(data = smaller) +
  geom_bin2d(mapping = aes(x = carat, y = price))

# install.packages("hexbin")
ggplot(data = smaller) +
  geom_hex(mapping = aes(x = carat, y = price))
```

Another option is to bin one continuous variable so it acts like a categorical variable. Then you can use one of the techniques for visualising the combination of a categorical and a continuous variable that you learned about. For example, you could bin `carat` and then for each group, display a boxplot:

```{r}
ggplot(data = smaller, mapping = aes(x = carat, y = price)) + 
  geom_boxplot(mapping = aes(group = cut_width(carat, 0.1)))
```

`cut_width(x, width)`, as used above, divides `x` into bins of width `width`. By default, boxplots look roughly the same (apart from number of outliers) regardless of how many observations there are, so it's difficult to tell that each boxplot summarises a different number of points. One way to show that is to make the width of the boxplot proportional to the number of points with `varwidth = TRUE`.

Another approach is to display approximately the same number of points in each bin. That's the job of `cut_number()`:

```{r}
ggplot(data = smaller, mapping = aes(x = carat, y = price)) + 
  geom_boxplot(mapping = aes(group = cut_number(carat, 20)))
```

#### Exercises

1.  Instead of summarising the conditional distribution with a boxplot, you
    could use a frequency polygon. What do you need to consider when using
    `cut_width()` vs `cut_number()`? How does that impact a visualisation of
    the 2d distribution of `carat` and `price`?

1.  Visualise the distribution of carat, partitioned by price.

1.  How does the price distribution of very large diamonds compare to small 
    diamonds. Is it as you expect, or does it surprise you?
    
1.  Combine two of the techniques you've learned to visualise the 
    combined distribution of cut, carat, and price.

1. Two dimensional plots reveal outliers that are not visible in one 
   dimensional plots. For example, some points in the plot below have an 
   unusual combination of `x` and `y` values, which makes the points outliers 
   even though their `x` and `y` values appear normal when examined separately.
  
    ```{r, dev = "png"}
    ggplot(data = diamonds) +
      geom_point(mapping = aes(x = x, y = y)) +
      coord_cartesian(xlim = c(4, 11), ylim = c(4, 11))
    ```
    
    Why is a scatterplot a better display than a binned plot for this case?

## Patterns and models

Patterns in your data provide clues about relationships. If a systematic relationship exists between two variables it will appear as a pattern in the data. If you spot a pattern, ask yourself:

+ Could this pattern be due to coincidence (i.e. random chance)?

+ How can you describe the relationship implied by the pattern?

+ How strong is the relationship implied by the pattern?

+ What other variables might affect the relationship?

+ Does the relationship change if you look at individual subgroups of the data?

A scatterplot of Old Faithful eruption lengths versus the wait time between eruptions shows a pattern: longer wait times are associated with longer eruptions. The scatterplot also displays the two clusters that we noticed above.

```{r fig.height = 2}
ggplot(data = faithful) + 
  geom_point(mapping = aes(x = eruptions, y = waiting))
``` 

Patterns provide one of the most useful tools for data scientists because they reveal covariation. If you think of variation as a phenomenon that creates uncertainty, covariation is a phenomenon that reduces it. If two variables covary, you can use the values of one variable to make better predictions about the values of the second. If the covariation is due to a causal relationship (a special case), then you can use the value of one variable to control the value of the second.

Models are a tool for extracting patterns out of data. For example, consider the diamonds data. It's hard to understand the relationship between cut and price, because cut and carat, and carat and price are tightly related. It's possible to use a model to remove the very strong relationship between price and carat so we can explore the subtleties that remain. The following code fits a model that predicts `price` from `carat` and then computes the residuals (the difference between the predicted value and the actual value). The residuals give us a view of the price of the diamond, once the effect of carat has been removed. 

```{r, dev = "png"}
library(modelr)

mod <- lm(log(price) ~ log(carat), data = diamonds)

diamonds2 <- diamonds %>% 
  add_residuals(mod) %>% 
  mutate(resid = exp(resid))

ggplot(data = diamonds2) + 
  geom_point(mapping = aes(x = carat, y = resid))
```

Once you've removed the strong relationship between carat and price, you can see what you expect in the relationship between cut and price: relative to their size, better quality diamonds are more expensive. 

```{r}
ggplot(data = diamonds2) + 
  geom_boxplot(mapping = aes(x = cut, y = resid))
```

You'll learn how models, and the modelr package, work in the final part of the book, [model](#model-intro). We're saving modelling for later because understanding what models are and how they work is easiest once you have tools of data wrangling and programming in hand.

## ggplot2 calls

As we move on from these introductory chapters, we'll transition to a more concise expression of ggplot2 code. So far we've been very explicit, which is helpful when you are learning:

```{r, eval = FALSE}
ggplot(data = faithful, mapping = aes(x = eruptions)) + 
  geom_freqpoly(binwidth = 0.25)
```

Typically, the first one or two arguments to a function are so important that you should know them by heart. The first two arguments to `ggplot()` are `data` and `mapping`, and the first two arguments to `aes()` are `x` and `y`. In the remainder of the book, we won't supply those names. That saves typing, and, by reducing the amount of boilerplate, makes it easier to see what's different between plots. That's a really important programming concern that we'll come back in [functions].

Rewriting the previous plot more concisely yields:

```{r, eval = FALSE}
ggplot(faithful, aes(eruptions)) + 
  geom_freqpoly(binwidth = 0.25)
```

Sometimes we'll turn the end of a pipeline of data transformation into a plot. Watch for the transition from `%>%` to `+`. I wish this transition wasn't necessary but unfortunately ggplot2 was created before the pipe was discovered.

```{r, eval = FALSE}
diamonds %>% 
  count(cut, clarity) %>% 
  ggplot(aes(clarity, cut, fill = n)) + 
    geom_tile()
```

## Learning more

If you want learn more about the mechanics of ggplot2, I'd highly recommend grabbing a copy of the ggplot2 book: <https://amzn.com/331924275X>. It's been recently updated, so it includes dplyr and tidyr code, and has much more space to explore all the facets of visualisation. Unfortunately the book isn't generally available for free, but if you have a connection to a university you can probably get an electronic version for free through SpringerLink.

Another useful resource is the [_R Graphics Cookbook_](https://amzn.com/1449316956) by Winston Chang. Much of the contents are available online at <http://www.cookbook-r.com/Graphs/>.

I also recommend [_Graphical Data Analysis with R_](https://amzn.com/1498715230), by Antony Unwin. This is a book-length treatment similar to the material covered in this chapter, but has the space to go into much greater depth. 
