# Introducción

La ciencia de los datos es una excitante disciplina que le permite convertir los datos sin procesar en comprensión, percepción y conocimiento. El objetivo de "R para Ciencia de los Datos" es ayudarle a aprender las herramientas más importantes en R que le permitirán hacer ciencia de datos. Después de leer este libro, usted tendrá las herramientas para abordar una amplia variedad de desafíos en ciencia de datos, utilizando las mejores partes de R.

## Lo que aprenderá

La ciencia de los datos es un campo enorme, y no hay forma de dominarlo leyendo un solo libro. El objetivo de este libro es darle una base sólida en las herramientas más importantes. Nuestro modelo de las herramientas necesarias en un proyecto típico de ciencia de datos se parece a esto:

```{r echo = FALSE, out.width = "75%"}
knitr::include_graphics("diagrams/data-science.png")
```

Lo primero que debe hacer es importar sus datos a R. Esto normalmente significa que usted toma datos almacenados en un archivo, una base de datos o una web API y los carga en un data frame en R. Si no puede llevar sus datos a R, ¡no podrá hacer ciencia de datos en él!

Una vez que haya importado sus datos, es una buena idea ordenarlos, es decir, hacer un proceso de __depuración__. Ordenar los datos significa almacenarlos de una forma consistente, que la semántica del conjunto de datos coincida con la forma en que se almacena. En resumen, cuando los datos están ordenados, cada columna es una variable y cada fila es una observación. Los datos ordenados son importantes porque la estructura consistente le permite centrar su atención en las preguntas sobre los datos, no luchar para tener los datos en la forma correcta para diferentes funciones.

Después de que haya datos ordenados, un primer paso común es __transformarlos__. La transformación incluye la focalización en las observaciones de interés (como todas las personas en una ciudad, o todos los datos del último año), la creación de nuevas variables que son funciones de las variables existentes (como la velocidad de cálculo de la rapidez y el tiempo), y el cálculo de un conjunto de estadísticas de resumen (como conteos o promedios). Juntos, ordenar y transformar se llaman __lidiar__, porque conseguir sus datos en una forma que sea natural de trabajar, a menudo, ¡se siente como una lucha!

Una vez que tenga datos ordenados con las variables que necesita, hay dos motores principales de generación de conocimiento: visualización y modelado. Éstos tienen fortalezas y debilidades complementarias así que cualquier análisis verdadero iterará entre ellos muchas veces.

La __Visualización__ es una actividad fundamentalmente humana. Una buena visualización le mostrará cosas que no esperaba, o plantear nuevas preguntas sobre los datos. Una buena visualización también podría sugerir que está haciendo la pregunta incorrecta, o necesita recoger datos diferentes. Las visualizaciones pueden sorprenderle, pero no se ajustan particularmente bien porque requieren que un humano las interprete.

Los __Modelos__ son herramientas complementarias a la visualización. Una vez que haya hecho sus preguntas lo suficientemente precisas, puede utilizar un modelo para responderlas. Los modelos son una herramienta fundamentalmente matemática o computacional, por lo que generalmente escalan bien. ¡Incluso cuando no lo hacen, es generalmente más barato comprar más computadoras que comprar más cerebros! Pero cada modelo hace suposiciones, y por su propia naturaleza un modelo no puede cuestionar sus propias suposiciones. Eso significa que un modelo no puede sorprenderlo.

El último paso de la ciencia de los datos es la __comunicación__, una parte absolutamente crítica de cualquier proyecto de análisis de datos. No importa qué tan bien estén sus modelos y si la visualización lo ha llevado a entender los datos, sino puede comunicar sus resultados a otros, fracasará.

Alrededor de todas estas herramientas está la __programación__. La programación es una herramienta transversal que se utiliza en todas las partes del proyecto. No es necesario ser un programador experto para ser un científico de datos, pero aprender más sobre la programación vale la pena porque convertirse en un mejor programador le permite automatizar tareas comunes y resolver nuevos problemas con mayor facilidad.

Usted usará estas herramientas en cada proyecto de ciencia de datos, pero para la mayoría de los proyectos no es suficiente. Hay una regla aproximada de 80-20 en juego; Puede abordar aproximadamente el 80% de cada proyecto utilizando las herramientas que aprenderá en este libro, pero necesitará otras herramientas para abordar el 20% restante. A lo largo de este libro le indicamos los recursos donde puede aprender más.

## Cómo se organiza este libro

La descripción anterior de las herramientas de la ciencia de datos se organiza aproximadamente de acuerdo con el orden en que se utilizan en un análisis (aunque, por supuesto, se iterará a través de ellas varias veces). En nuestra experiencia, sin embargo, esta no es la mejor manera de aprender:

* Comenzar con la ingesta y el ordenamiento de datos es subóptimo porque el   80% del tiempo es rutinario y aburrido, y el otro 20% del tiempo es         extraño y frustrante. ¡Es un mal lugar para empezar a aprender un nuevo     tema! En vez de eso, comenzaremos con la visualización y transformación de   datos que ya han sido importados y ordenados. De esta manera, cuando        ingiera y arregle sus propios datos, la motivación se mantendrá alta        puesto que sabe que el dolor vale la pena.
  
* Algunos temas se explican mejor con otras herramientas. Por ejemplo,        creemos que es más fácil entender cómo funcionan los modelos si ya sabe     sobre visualización, ordenación de datos y programación.
  
* Las herramientas de programación no son necesariamente interesantes por     derecho propio, pero sí le permiten abordar problemas mucho más difíciles.   Le daremos una selección de herramientas de programación en la mitad del    libro, y, de esta forma, usted verá que pueden combinarse con las           herramientas de ciencia de datos para abordar problemas de modelado        interesantes.

Dentro de cada capítulo, tratamos de atenernos a un patrón similar: comenzar con algunos ejemplos de motivación para que pueda ver la imagen ampliada, y luego sumergirse en los detalles. Cada sección del libro se combina con ejercicios para ayudarlo a practicar lo que ha aprendido. Si bien es tentador omitir los ejercicios, no hay mejor manera de aprender que practicar con problemas reales.

## Lo que no aprenderá

Hay algunos temas importantes que este libro no cubre. Creemos que es importante mantenerse enfocados inexorablemente en lo esencial para que pueda ponerse en marcha lo más rápido posible. Eso significa que este libro no puede cubrir cada tema importante.

### Big data

Este libro orgullosamente se centra en pequeños conjuntos de datos en la memoria. Este es el lugar adecuado para comenzar porque no puede abordar grandes datos a menos que tenga experiencia con datos pequeños. Las herramientas que aprenderá en este libro manejarán fácilmente cientos de megabytes de datos y, con un poco de cuidado, típicamente se pueden utilizar para trabajar con 1-2 Gb de datos. Si trabaja rutinariamente con datos más grandes (10-100 Gb, digamos), debe aprender más sobre [data.table](https://github.com/Rdatatable/data.table). Este libro no enseña data.table porque tiene una interfaz muy concisa que lo hace más difícil de aprender ya que ofrece menos pistas lingüísticas. Pero si usted está trabajando con datos grandes, la recompensa del funcionamiento se recompensa con el esfuerzo adicional requerido para aprenderlo.

Si sus datos son más grandes que esto, considere cuidadosamente si su gran problema de datos podría ser un pequeño problema de datos disfrazado. Aunque los datos completos pueden ser grandes, a menudo los datos necesarios para responder a una pregunta específica son pequeños. Es posible que encuentre un subconjunto, una submuestra o un resumen que encaje en la memoria y le permita responder a la pregunta que le interesa. El reto aquí es encontrar los datos pequeños adecuados, que a menudo requieren mucha iteración.

Otra posibilidad es que su gran problema de datos sea en realidad un gran número de pequeños problemas de datos. Cada problema individual podría encajar en la memoria, pero usted tiene millones de ellos. Por ejemplo, es posible que desee adaptar un modelo a cada persona en su conjunto de datos. Eso sería trivial si tuviera sólo 10 o 100 personas, pero en su lugar tiene un millón. Afortunadamente, cada problema es independiente de los demás (una configuración que a veces se llama paralelo vergonzoso), por lo que sólo necesita un sistema (como Hadoop o Spark) que le permita enviar diferentes conjuntos de datos a diferentes ordenadores para su procesamiento. Una vez que haya descubierto cómo responder a la pregunta de un solo subconjunto utilizando las herramientas descritas en este libro, aprenderá nuevas herramientas como sparklyr, rhipe y ddr para resolverlo para el conjunto de datos completo.

### Python, Julia, y sus amigos

En este libro, usted no aprenderá nada sobre Python, Julia, o cualquier otro lenguaje de programación útil para la ciencia de los datos. Esto no es porque pensemos que estas herramientas son malas. ¡No lo son! Y en la práctica, la mayoría de los equipos de ciencia de datos utiliza una mezcla de idiomas, a menudo al menos R y Python.

Sin embargo, creemos firmemente que es mejor dominar una herramienta a la vez. Usted conseguirá mejores resultados, más rápidamente si se zambulle profundo, algo diferente a si se separa sobre muchos asuntos al tiempo. Esto no significa que sólo deba saber una cosa, sólo que generalmente aprenderá más rápido si se apega a una cosa a la vez. Debe esforzarse para aprender nuevas cosas a lo largo de su carrera, pero asegúrese de que su comprensión sea sólida antes de pasar a la siguiente cosa interesante.

Creemos que R es un gran lugar para comenzar su viaje de ciencia de datos porque es un entorno diseñado desde cero para apoyar la ciencia de los datos. R no es sólo un lenguaje de programación, sino que también es un entorno interactivo para hacer ciencia de datos. Para apoyar la interacción, R es un lenguaje mucho más flexible que muchos de sus pares. Esta flexibilidad viene con sus desventajas, pero la gran ventaja es lo fácil que es evolucionar las gramáticas personalizadas para partes específicas del proceso de la ciencia de datos. Estos mini idiomas le ayudan a pensar en los problemas como científico de datos, al tiempo que apoyan la interacción fluida entre su cerebro y la computadora.

### Datos no rectangulares

Este libro se centra exclusivamente en datos rectangulares: colecciones de valores que están asociados a una variable y una observación. Hay muchos conjuntos de datos que no encajan naturalmente en este paradigma: incluyendo imágenes, sonidos, árboles y texto. Pero los marcos de datos rectangulares son extremadamente comunes en la ciencia y la industria, y creemos que son un gran lugar para comenzar su viaje de ciencia de datos.

### Confirmación de hipótesis

Es posible dividir el análisis de datos en dos campos: generación de hipótesis y confirmación de hipótesis (a veces llamado análisis confirmatorio). El foco de este libro es descaradamente sobre la generación de hipótesis, o exploración de datos. Aquí buscará profundamente los datos y, en combinación con su conocimiento de la materia, generará muchas hipótesis interesantes para ayudar a explicar porqué los datos se comportan de la manera que lo hace. Usted evalúa las hipótesis informalmente, usando su escepticismo para desafiar los datos de múltiples maneras.

El complemento de la generación de hipótesis es la confirmación de la hipótesis. La confirmación de la hipótesis es difícil por dos razones:

1.  Se necesita un modelo matemático preciso para generar predicciones          verificables. Esto a menudo requiere una considerable sofisticación         estadística.

1.  Sólo puede utilizar una observación una vez para confirmar una              hipótesis. Tan pronto como se utiliza más de una vez, está volviendo a      hacer el análisis exploratorio.
    Esto significa que para hacer la confirmación de la hipótesis, necesita     para "preregistrar" (escribir por adelantado) su plan de análisis, y no     desviarse de él, incluso cuando haya visto los datos. Vamos a hablar un     poco sobre algunas estrategias que puede utilizar para hacer esto más       fácil en [modelado](#model-intro).

Es común pensar en el modelado como una herramienta para la confirmación de la hipótesis, y la visualización como una herramienta para la generación de hipótesis. Pero eso es una falsa dicotomía: los modelos se utilizan a menudo para la exploración, y con un poco de cuidado se puede utilizar la visualización para la confirmación. La diferencia clave es la frecuencia con que observas cada observación: si miras solo una vez, es confirmación; Si miras más de una vez, es exploración.

## Prerequisitos

Hemos hecho algunas suposiciones acerca de lo que ya sabe para sacar el máximo provecho de este libro. Usted debe estar familizarizado con el manejo numérico, y es útil si ya tiene alguna experiencia de programación. Si nunca ha programado antes, puede encontrar en [Hands on Programming with R](http://amzn.com/1449359019) de Garrett un buen complemento de este libro.

Hay cuatro cosas que necesita para ejecutar el código en este libro: R, RStudio, una colección de paquetes R llamado __tidyverse__, y un puñado de otros paquetes. Los paquetes son las unidades fundamentales del código R reproducible. Incluyen funciones reutilizables, la documentación que describe cómo usarlas y datos de ejemplo.

### R 

Para descargar R, vaya al CRAN, **c**omprehensive **R** **a**rchive **n**etwork. El CRAN se compone de un conjunto de servidores espejo distribuidos alrededor del mundo y se usa para distribuir R y sus paquetes. No intente escoger un servidor espejo que esté cerca de usted, en lugar de escoger el espejo de la nube, <https://cloud.r-project.org>, que automáticamente lo hace por usted.

Una nueva versión principal de R sale una vez al año, y hay 2-3 lanzamientos menores cada año. Es una buena idea actualizarlo regularmente. Actualizar puede ser un poco complicado, especialmente para las versiones principales, que requieren que reinstale todos sus paquetes, pero dejar así lo empeora.

### RStudio

RStudio es un entorno de desarrollo integrado, o IDE, para la programación de R. Descárguelo e instálelo desde <http://www.rstudio.com/download>. RStudio se actualiza un par de veces al año. Cuando una nueva versión está disponible, RStudio le informará. Es una buena idea actualizar regularmente para que pueda aprovechar las últimas y mejores características. Para este libro, asegúrese de tener RStudio 1.0.0.

Al iniciar RStudio, verá dos regiones clave en la interfaz:

```{r echo = FALSE, out.width = "75%"}
knitr::include_graphics("diagrams/rstudio-console.png")
```

Por ahora, todo lo que necesita saber es que usted escribe código R en el panel de la consola y pulsa enter para ejecutarlo. ¡Aprenderá más a medida que avancemos!

### tidyverse

También necesitará instalar algunos paquetes R. Un _package_ R es una colección de funciones, datos y documentación que amplía las capacidades de la base R. El uso de paquetes es clave para el uso exitoso de R. La mayoría de los paquetes que usted aprenderá en este libro son parte de la denominada tidyverse. Los paquetes en el tidyverse comparten una filosofía común de datos y programación R, y están diseñados para trabajar juntos de forma natural.

Puede instalar el tidyverse completo con una sola línea de código:

```{r, eval = FALSE}
install.packages("tidyverse")
```

En su propia computadora, escriba esa línea de código en la consola y, a continuación, presione Intro para ejecutarla. R descargará los paquetes de CRAN y los instalará en su computadora. Si tiene problemas para instalar, asegúrese de que está conectado a Internet y de que <https://cloud.r-project.org/> no está bloqueado por su servidor de seguridad o proxy.

No podrá utilizar las funciones, los objetos y los archivos de ayuda en un paquete hasta que lo cargue con `library ()`. Una vez que haya instalado un paquete, puede cargarlo con la función `library ()`:

```{r}
library(tidyverse)
```

Esto le dice que tidyverse está cargando los paquetes ggplot2, tibble, tidyr, readr, purrr y dplyr. Estos son considerados los __core__ del tidyverse porque los usará en casi todos los análisis.

Los paquetes en el tidyverse cambian bastante frecuentemente. Puede ver si hay actualizaciones disponibles e instalarlas opcionalmente ejecutando `tidyverse_update()`.

### Otros paquetes

Hay muchos otros paquetes excelentes que no son parte del tidyverse, porque resuelven problemas en un diverso dominio, o son diseñados con un diverso sistema de principios subyacentes. Esto no los hace mejores o peores, apenas diferentes. En otras palabras, el complemento al tidyverse no es el messyverse, sino muchos otros universos de paquetes interrelacionados. A medida que aborde más proyectos de ciencia de datos con R, aprenderá nuevos paquetes y nuevas formas de pensar acerca de los datos.

En este libro usaremos tres paquetes de datos fuera del tidyverse:

```{r, eval = FALSE}
install.packages(c("nycflights13", "gapminder", "Lahman"))
```

Estos paquetes proporcionan datos sobre vuelos aéreos, desarrollo mundial y béisbol que usaremos para ilustrar ideas claves sobre ciencia de datos.

## Compilando código en R

La sección anterior le mostró un par de ejemplos de ejecutar código en R. El código en el libro se ve así:

```{r, eval = TRUE}
1 + 2
#> [1] 3
```

Si ejecuta el mismo código en su consola local, se verá así:

```
> 1 + 2
[1] 3
```

Hay dos diferencias principales. En la consola, usted escribe después del `>`, llamado el __prompt__; no mostraremos el prompt en el libro. en el libro, la salida se comenta con `#>`; en la consola aparece directamente después de su código. Estas dos diferencias significan que si está trabajando con una versión electrónica del libro, puede copiar fácilmente el código del libro y dentro de la consola.

A lo largo del libro usamos un conjunto consistente de convenciones para referirnos al código:

* Las funciones están en una fuente de código y seguidas por paréntesis,      como `sum()`, o `mean()`.

* Otros objetos en R (como datos o argumentos de función) están en una        fuente de código, sin paréntesis, como `flights` o `x`.
  
* Si queremos dejar claro de qué paquete proviene un objeto, usaremos el      nombre del paquete seguido de dos puntos, como `dplyr::mutate()`, o   
  `nycflights13::flights`. Este es también código R válido.

## Obtener ayuda y aprender más

Este libro no es una isla; no hay ningún recurso que le permita dominar R. A medida que empiece a aplicar las técnicas descritas en este libro a sus propios datos, pronto encontrará preguntas que no conteste. Esta sección describe algunos consejos sobre cómo obtener ayuda y cómo ayudarle a seguir aprendiendo.

Si se queda atascado, empiece con Google. Normalmente agregar "R" a una consulta es suficiente para restringirlo a resultados relevantes: si la búsqueda no es útil, significa que no hay ningún resultado específico de R disponible. Google es particularmente útil para mensajes de error. Si recibe un mensaje de error y no tiene idea de lo que significa, ¡intente buscar en Google! Lo más probable es que alguien más haya tenido el mismo problema en el pasado, y habrá ayuda en algún lugar de la web. (Si el mensaje de error no está en inglés, ejecute `Sys.setenv(LANGUAGE = "en")` y vuelva a ejecutar el código; es más probable que encuentre ayuda para mensajes de error en inglés.)

Si Google no le ayuda, intente [stackoverflow](http://stackoverflow.com). Comience por pasar un poco de tiempo buscando una respuesta existente, incluyendo `[R]` restrinja su búsqueda a preguntas y respuestas que usan R. Si no encuentra nada útil, prepare un ejemplo reproducible mínimo o use __reprex__ ((repr)oducible (ex)ample, en inglés).  Un buen reprex hace que sea más fácil para otras personas ayudarle, y con frecuencia usted descubrirá la solución del problema en el trascurso del tiempo.

Hay tres cosas que debe incluir para que su ejemplo sea reproducible: paquetes, datos y código necesarios.

1.  Los **Paquetes** deben cargarse en la parte superior del script, por lo     que es fácil ver cuáles son las necesidades del ejemplo. Este es un buen     momento para comprobar que está utilizando la última versión de cada        paquete; Es posible que haya descubierto un error que se ha corregido       desde que instaló el paquete. Para paquetes en el tidyverse, la manera      más fácil de comprobar es ejecutar `tidyverse_update()`.

1.  El camino más fácil pra incluir **datos** en una pregunta es usar `dput()` para generar el código en R y recrearlo. Por ejemplo, para recrear el conjunto de datos `mtcars` en R, realizaría los siguientes pasos:
  
    1. Ejecute `dput(mtcars)` en R
    2. Copie la salida
    3. En mi script reproducible, escriba `mtcars <- ` lueg pegue.
    
    Trate de encontrar el subconjunto más pequeño de sus datos que todavía      revela el problema.

1.  Pase un poco de tiempo asegurándose de que su ** código ** sea fácil de leer para otros:

    * Asegúrese de haber utilizado espacios y que los nombres de sus              variables sean concisos, pero informativos.
    
    * Utilice los comentarios para indicar dónde se encuentra su problema.
    
    * Haga todo lo posible para eliminar todo lo que no está relacionado con       el problema.  
    
      Cuanto más corto sea el código, más fácil será entenderlo y más fácil       será arreglarlo.

Finalice comprobando que ha hecho un ejemplo reproducible iniciando una nueva sesión R y copiando y pegando el script.

También debe pasar algún tiempo preparándose para resolver problemas antes de que ocurran. Invertir un poco de tiempo en el aprendizaje de R cada día pagará generosamente a largo plazo. Una forma es seguir lo que Hadley, Garrett y todos los demás en RStudio están haciendo en el [Blog de RStudio](https://blog.rstudio.org). Aquí es donde publicamos anuncios sobre nuevos paquetes, nuevas características de la IDE y cursos en vivo. También es posible que desee seguir a Hadley ([\@hadleywickham](https://twitter.com/hadleywickham)) o a Garrett ([\@statgarrett](https://twitter.com/statgarrett)) en Twitter, o siga [\@rstudiotips](https://twitter.com/rstudiotips) para mantenerse al día con todas las actualizaciones de la IDE.

Para mantenerse al día con la comunidad de R más ampliamente, le recomendamos leer <http://www.r-bloggers.com>: agrega más de 500 blogs sobre R de todo el mundo. Si es un usuario activo de Twitter, siga el hashtag `#rstats`. Twitter es una de las herramientas clave que Hadley utiliza para mantenerse al día con los nuevos desarrollos en la comunidad.

## Agradecimientos

Este libro no es sólo el producto de Hadley y Garrett, sino que es el resultado de muchas conversaciones (en persona y en línea) que hemos tenido con muchas personas de la comunidad de R. Hay algunas personas a las que nos gustaría agradecer en particular, porque han pasado muchas horas respondiendo a nuestras preguntas tontas y ayudándonos a pensar mejor en la ciencia de los datos:

* Jenny Bryan y Lionel Henry por muchas discusiones útiles sobre cómo         trabajar con listas y columnas de listas.
  
* Los tres capítulos sobre flujo de trabajo fueron adaptados (con permiso),   de  <http://stat545.com/block002_hello-r-workspace-wd-project.html> por 
  Jenny Bryan.

* Genevera Allen por discusiones sobre modelos, modelización, perspectiva de aprendizaje estadístico, y la diferencia entre la generación de hipótesis y la confirmación de hipótesis.

* Yihui Xie por su trabajo con el paquete                                     [bookdown](https://github.com/rstudio/bookdown) y por responder             incansablemente a mis solicitudes de funciones.

* Bill Behrman por su lectura reflexiva de todo el libro, y por probarlo con su clase de ciencia de datos en Stanford.

* La comunidad de twitter de \#rstats quien revisó todos los capítulos del    proyecto y proporcionó un montón de comentarios útiles.

* Tal Galili por aumentar su paquete dendextend para apoyar una sección       sobre agrupación que no lo hizo en el borrador final.

Este libro se escribió abiertamente, y muchas personas contribuyeron a solicitar peticiones para solucionar problemas menores. Un agradecimiento especial a todos los que han contribuido a través de GitHub:

```{r, results = "asis", echo = FALSE, message = FALSE}
library(dplyr)
# git --no-pager shortlog -ns > contribs.txt
contribs <- readr::read_tsv("contribs.txt", col_names = c("n", "name"))

contribs <- contribs %>% 
  filter(!name %in% c("hadley", "Garrett", "Hadley Wickham",
                      "Garrett Grolemund")) %>% 
  arrange(name) %>% 
  mutate(uname = ifelse(!grepl(" ", name), paste0("@", name), name))

cat("Thanks go to all contributers in alphabetical order: ")
cat(paste0(contribs$uname, collapse = ", "))
cat(".\n")
```

## Colofón

Una versión en línea de este libro está disponible en <http://r4ds.had.co.nz>. Continuará evolucionando entre reimpresiones del libro físico. La fuente del libro está disponible en <https://github.com/hadley/r4ds>. El libro está soportado por <https://bookdown.org> que hace que sea fácil de convertir archivos R markdown en HTML, PDF y EPUB.

Este libro fue hecho con:

```{r}
devtools::session_info(c("tidyverse"))
```
